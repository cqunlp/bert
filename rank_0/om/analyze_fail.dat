# 1.This file shows the parsed IR info when graph evaluating failed to help find the problem.
# 2.You can search the last `------------------------>` to the node which is inferred failed.
# 3.Refer to https://www.mindspore.cn/search?inputValue=analyze_fail.dat to get more instructions.
# ===============================================================================

# [No.1] construct_wrapper.178
# In file /data0/bert/src/bert.py(398)/    def construct(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None,/
funcgraph fg_178(
        %para1 : Tensor(I32)[512, 128]    # input_ids
        , %para2 : Tensor(I32)[512, 128]    # attention_mask
        , %para3 : Tensor(I32)[512, 128]    # token_type_ids
        , %para4 : NoneTypeNoShape    # position_ids
        , %para5 : NoneTypeNoShape    # head_mask
        , %para6 : Tensor(I32)[512, 20]    # masked_lm_labels
        , %para7 : Tensor(I32)[512, 1]    # next_sentence_label
        , %para8 : Ref[Tensor(F32)][30522]    # cls.predictions.bias
        , %para9 : Ref[Tensor(F32)][2]    # cls.seq_relationship.bias
        , %para10 : Ref[Tensor(F32)][2, 768]    # cls.seq_relationship.weight
        , %para11 : Ref[Tensor(F32)][768]    # cls.predictions.transform.layer_norm.gamma
        , %para12 : Ref[Tensor(F32)][768]    # cls.predictions.transform.layer_norm.beta
        , %para13 : Ref[Tensor(F32)][30522, 768]    # bert.embeddings.word_embeddings.embedding_table
        , %para14 : Ref[Tensor(F32)][768]    # bert.pooler.dense.bias
        , %para15 : Ref[Tensor(F32)][768, 768]    # bert.pooler.dense.weight
        , %para16 : Ref[Tensor(F32)][768]    # cls.predictions.transform.dense.bias
        , %para17 : Ref[Tensor(F32)][768, 768]    # cls.predictions.transform.dense.weight
        , %para18 : Ref[Tensor(F32)][768]    # bert.embeddings.layer_norm.gamma
        , %para19 : Ref[Tensor(F32)][768]    # bert.embeddings.layer_norm.beta
        , %para20 : Ref[Tensor(F32)][2, 768]    # bert.embeddings.token_type_embeddings.embedding_table
        , %para21 : Ref[Tensor(F32)][512, 768]    # bert.embeddings.position_embeddings.embedding_table
        , %para22 : Ref[Tensor(F32)][768]    # bert.encoder.layer.0.output.layer_norm.gamma
        , %para23 : Ref[Tensor(F32)][768]    # bert.encoder.layer.0.output.layer_norm.beta
        , %para24 : Ref[Tensor(F32)][768]    # bert.encoder.layer.1.output.layer_norm.gamma
        , %para25 : Ref[Tensor(F32)][768]    # bert.encoder.layer.1.output.layer_norm.beta
        , %para26 : Ref[Tensor(F32)][768]    # bert.encoder.layer.2.output.layer_norm.gamma
        , %para27 : Ref[Tensor(F32)][768]    # bert.encoder.layer.2.output.layer_norm.beta
        , %para28 : Ref[Tensor(F32)][768]    # bert.encoder.layer.3.output.layer_norm.gamma
        , %para29 : Ref[Tensor(F32)][768]    # bert.encoder.layer.3.output.layer_norm.beta
        , %para30 : Ref[Tensor(F32)][768]    # bert.encoder.layer.4.output.layer_norm.gamma
        , %para31 : Ref[Tensor(F32)][768]    # bert.encoder.layer.4.output.layer_norm.beta
        , %para32 : Ref[Tensor(F32)][768]    # bert.encoder.layer.5.output.layer_norm.gamma
        , %para33 : Ref[Tensor(F32)][768]    # bert.encoder.layer.5.output.layer_norm.beta
        , %para34 : Ref[Tensor(F32)][768]    # bert.encoder.layer.6.output.layer_norm.gamma
        , %para35 : Ref[Tensor(F32)][768]    # bert.encoder.layer.6.output.layer_norm.beta
        , %para36 : Ref[Tensor(F32)][768]    # bert.encoder.layer.7.output.layer_norm.gamma
        , %para37 : Ref[Tensor(F32)][768]    # bert.encoder.layer.7.output.layer_norm.beta
        , %para38 : Ref[Tensor(F32)][768]    # bert.encoder.layer.8.output.layer_norm.gamma
        , %para39 : Ref[Tensor(F32)][768]    # bert.encoder.layer.8.output.layer_norm.beta
        , %para40 : Ref[Tensor(F32)][768]    # bert.encoder.layer.9.output.layer_norm.gamma
        , %para41 : Ref[Tensor(F32)][768]    # bert.encoder.layer.9.output.layer_norm.beta
        , %para42 : Ref[Tensor(F32)][768]    # bert.encoder.layer.10.output.layer_norm.gamma
        , %para43 : Ref[Tensor(F32)][768]    # bert.encoder.layer.10.output.layer_norm.beta
        , %para44 : Ref[Tensor(F32)][768]    # bert.encoder.layer.11.output.layer_norm.gamma
        , %para45 : Ref[Tensor(F32)][768]    # bert.encoder.layer.11.output.layer_norm.beta
        , %para46 : Ref[Tensor(F32)][768]    # bert.encoder.layer.0.attention.output.layer_norm.gamma
        , %para47 : Ref[Tensor(F32)][768]    # bert.encoder.layer.0.attention.output.layer_norm.beta
        , %para48 : Ref[Tensor(F32)][768]    # bert.encoder.layer.1.attention.output.layer_norm.gamma
        , %para49 : Ref[Tensor(F32)][768]    # bert.encoder.layer.1.attention.output.layer_norm.beta
        , %para50 : Ref[Tensor(F32)][768]    # bert.encoder.layer.2.attention.output.layer_norm.gamma
        , %para51 : Ref[Tensor(F32)][768]    # bert.encoder.layer.2.attention.output.layer_norm.beta
        , %para52 : Ref[Tensor(F32)][768]    # bert.encoder.layer.3.attention.output.layer_norm.gamma
        , %para53 : Ref[Tensor(F32)][768]    # bert.encoder.layer.3.attention.output.layer_norm.beta
        , %para54 : Ref[Tensor(F32)][768]    # bert.encoder.layer.4.attention.output.layer_norm.gamma
        , %para55 : Ref[Tensor(F32)][768]    # bert.encoder.layer.4.attention.output.layer_norm.beta
        , %para56 : Ref[Tensor(F32)][768]    # bert.encoder.layer.5.attention.output.layer_norm.gamma
        , %para57 : Ref[Tensor(F32)][768]    # bert.encoder.layer.5.attention.output.layer_norm.beta
        , %para58 : Ref[Tensor(F32)][768]    # bert.encoder.layer.6.attention.output.layer_norm.gamma
        , %para59 : Ref[Tensor(F32)][768]    # bert.encoder.layer.6.attention.output.layer_norm.beta
        , %para60 : Ref[Tensor(F32)][768]    # bert.encoder.layer.7.attention.output.layer_norm.gamma
        , %para61 : Ref[Tensor(F32)][768]    # bert.encoder.layer.7.attention.output.layer_norm.beta
        , %para62 : Ref[Tensor(F32)][768]    # bert.encoder.layer.8.attention.output.layer_norm.gamma
        , %para63 : Ref[Tensor(F32)][768]    # bert.encoder.layer.8.attention.output.layer_norm.beta
        , %para64 : Ref[Tensor(F32)][768]    # bert.encoder.layer.9.attention.output.layer_norm.gamma
        , %para65 : Ref[Tensor(F32)][768]    # bert.encoder.layer.9.attention.output.layer_norm.beta
        , %para66 : Ref[Tensor(F32)][768]    # bert.encoder.layer.10.attention.output.layer_norm.gamma
        , %para67 : Ref[Tensor(F32)][768]    # bert.encoder.layer.10.attention.output.layer_norm.beta
        , %para68 : Ref[Tensor(F32)][768]    # bert.encoder.layer.11.attention.output.layer_norm.gamma
        , %para69 : Ref[Tensor(F32)][768]    # bert.encoder.layer.11.attention.output.layer_norm.beta
        , %para70 : Ref[Tensor(F32)][3072]    # bert.encoder.layer.0.intermediate.dense.bias
        , %para71 : Ref[Tensor(F32)][3072, 768]    # bert.encoder.layer.0.intermediate.dense.weight
        , %para72 : Ref[Tensor(F32)][3072]    # bert.encoder.layer.1.intermediate.dense.bias
        , %para73 : Ref[Tensor(F32)][3072, 768]    # bert.encoder.layer.1.intermediate.dense.weight
        , %para74 : Ref[Tensor(F32)][3072]    # bert.encoder.layer.2.intermediate.dense.bias
        , %para75 : Ref[Tensor(F32)][3072, 768]    # bert.encoder.layer.2.intermediate.dense.weight
        , %para76 : Ref[Tensor(F32)][3072]    # bert.encoder.layer.3.intermediate.dense.bias
        , %para77 : Ref[Tensor(F32)][3072, 768]    # bert.encoder.layer.3.intermediate.dense.weight
        , %para78 : Ref[Tensor(F32)][3072]    # bert.encoder.layer.4.intermediate.dense.bias
        , %para79 : Ref[Tensor(F32)][3072, 768]    # bert.encoder.layer.4.intermediate.dense.weight
        , %para80 : Ref[Tensor(F32)][3072]    # bert.encoder.layer.5.intermediate.dense.bias
        , %para81 : Ref[Tensor(F32)][3072, 768]    # bert.encoder.layer.5.intermediate.dense.weight
        , %para82 : Ref[Tensor(F32)][3072]    # bert.encoder.layer.6.intermediate.dense.bias
        , %para83 : Ref[Tensor(F32)][3072, 768]    # bert.encoder.layer.6.intermediate.dense.weight
        , %para84 : Ref[Tensor(F32)][3072]    # bert.encoder.layer.7.intermediate.dense.bias
        , %para85 : Ref[Tensor(F32)][3072, 768]    # bert.encoder.layer.7.intermediate.dense.weight
        , %para86 : Ref[Tensor(F32)][3072]    # bert.encoder.layer.8.intermediate.dense.bias
        , %para87 : Ref[Tensor(F32)][3072, 768]    # bert.encoder.layer.8.intermediate.dense.weight
        , %para88 : Ref[Tensor(F32)][3072]    # bert.encoder.layer.9.intermediate.dense.bias
        , %para89 : Ref[Tensor(F32)][3072, 768]    # bert.encoder.layer.9.intermediate.dense.weight
        , %para90 : Ref[Tensor(F32)][3072]    # bert.encoder.layer.10.intermediate.dense.bias
        , %para91 : Ref[Tensor(F32)][3072, 768]    # bert.encoder.layer.10.intermediate.dense.weight
        , %para92 : Ref[Tensor(F32)][3072]    # bert.encoder.layer.11.intermediate.dense.bias
        , %para93 : Ref[Tensor(F32)][3072, 768]    # bert.encoder.layer.11.intermediate.dense.weight
        , %para94 : Ref[Tensor(F32)][768]    # bert.encoder.layer.0.output.dense.bias
        , %para95 : Ref[Tensor(F32)][768, 3072]    # bert.encoder.layer.0.output.dense.weight
        , %para96 : Ref[Tensor(F32)][768]    # bert.encoder.layer.1.output.dense.bias
        , %para97 : Ref[Tensor(F32)][768, 3072]    # bert.encoder.layer.1.output.dense.weight
        , %para98 : Ref[Tensor(F32)][768]    # bert.encoder.layer.2.output.dense.bias
        , %para99 : Ref[Tensor(F32)][768, 3072]    # bert.encoder.layer.2.output.dense.weight
        , %para100 : Ref[Tensor(F32)][768]    # bert.encoder.layer.3.output.dense.bias
        , %para101 : Ref[Tensor(F32)][768, 3072]    # bert.encoder.layer.3.output.dense.weight
        , %para102 : Ref[Tensor(F32)][768]    # bert.encoder.layer.4.output.dense.bias
        , %para103 : Ref[Tensor(F32)][768, 3072]    # bert.encoder.layer.4.output.dense.weight
        , %para104 : Ref[Tensor(F32)][768]    # bert.encoder.layer.5.output.dense.bias
        , %para105 : Ref[Tensor(F32)][768, 3072]    # bert.encoder.layer.5.output.dense.weight
        , %para106 : Ref[Tensor(F32)][768]    # bert.encoder.layer.6.output.dense.bias
        , %para107 : Ref[Tensor(F32)][768, 3072]    # bert.encoder.layer.6.output.dense.weight
        , %para108 : Ref[Tensor(F32)][768]    # bert.encoder.layer.7.output.dense.bias
        , %para109 : Ref[Tensor(F32)][768, 3072]    # bert.encoder.layer.7.output.dense.weight
        , %para110 : Ref[Tensor(F32)][768]    # bert.encoder.layer.8.output.dense.bias
        , %para111 : Ref[Tensor(F32)][768, 3072]    # bert.encoder.layer.8.output.dense.weight
        , %para112 : Ref[Tensor(F32)][768]    # bert.encoder.layer.9.output.dense.bias
        , %para113 : Ref[Tensor(F32)][768, 3072]    # bert.encoder.layer.9.output.dense.weight
        , %para114 : Ref[Tensor(F32)][768]    # bert.encoder.layer.10.output.dense.bias
        , %para115 : Ref[Tensor(F32)][768, 3072]    # bert.encoder.layer.10.output.dense.weight
        , %para116 : Ref[Tensor(F32)][768]    # bert.encoder.layer.11.output.dense.bias
        , %para117 : Ref[Tensor(F32)][768, 3072]    # bert.encoder.layer.11.output.dense.weight
        , %para118 : Ref[Tensor(F32)][768]    # bert.encoder.layer.0.attention.output.dense.bias
        , %para119 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.0.attention.output.dense.weight
        , %para120 : Ref[Tensor(F32)][768]    # bert.encoder.layer.1.attention.output.dense.bias
        , %para121 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.1.attention.output.dense.weight
        , %para122 : Ref[Tensor(F32)][768]    # bert.encoder.layer.2.attention.output.dense.bias
        , %para123 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.2.attention.output.dense.weight
        , %para124 : Ref[Tensor(F32)][768]    # bert.encoder.layer.3.attention.output.dense.bias
        , %para125 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.3.attention.output.dense.weight
        , %para126 : Ref[Tensor(F32)][768]    # bert.encoder.layer.4.attention.output.dense.bias
        , %para127 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.4.attention.output.dense.weight
        , %para128 : Ref[Tensor(F32)][768]    # bert.encoder.layer.5.attention.output.dense.bias
        , %para129 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.5.attention.output.dense.weight
        , %para130 : Ref[Tensor(F32)][768]    # bert.encoder.layer.6.attention.output.dense.bias
        , %para131 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.6.attention.output.dense.weight
        , %para132 : Ref[Tensor(F32)][768]    # bert.encoder.layer.7.attention.output.dense.bias
        , %para133 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.7.attention.output.dense.weight
        , %para134 : Ref[Tensor(F32)][768]    # bert.encoder.layer.8.attention.output.dense.bias
        , %para135 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.8.attention.output.dense.weight
        , %para136 : Ref[Tensor(F32)][768]    # bert.encoder.layer.9.attention.output.dense.bias
        , %para137 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.9.attention.output.dense.weight
        , %para138 : Ref[Tensor(F32)][768]    # bert.encoder.layer.10.attention.output.dense.bias
        , %para139 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.10.attention.output.dense.weight
        , %para140 : Ref[Tensor(F32)][768]    # bert.encoder.layer.11.attention.output.dense.bias
        , %para141 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.11.attention.output.dense.weight
        , %para142 : Ref[Tensor(F32)][768]    # bert.encoder.layer.0.attention.self_attn.query.bias
        , %para143 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.0.attention.self_attn.query.weight
        , %para144 : Ref[Tensor(F32)][768]    # bert.encoder.layer.1.attention.self_attn.query.bias
        , %para145 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.1.attention.self_attn.query.weight
        , %para146 : Ref[Tensor(F32)][768]    # bert.encoder.layer.2.attention.self_attn.query.bias
        , %para147 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.2.attention.self_attn.query.weight
        , %para148 : Ref[Tensor(F32)][768]    # bert.encoder.layer.3.attention.self_attn.query.bias
        , %para149 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.3.attention.self_attn.query.weight
        , %para150 : Ref[Tensor(F32)][768]    # bert.encoder.layer.4.attention.self_attn.query.bias
        , %para151 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.4.attention.self_attn.query.weight
        , %para152 : Ref[Tensor(F32)][768]    # bert.encoder.layer.5.attention.self_attn.query.bias
        , %para153 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.5.attention.self_attn.query.weight
        , %para154 : Ref[Tensor(F32)][768]    # bert.encoder.layer.6.attention.self_attn.query.bias
        , %para155 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.6.attention.self_attn.query.weight
        , %para156 : Ref[Tensor(F32)][768]    # bert.encoder.layer.7.attention.self_attn.query.bias
        , %para157 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.7.attention.self_attn.query.weight
        , %para158 : Ref[Tensor(F32)][768]    # bert.encoder.layer.8.attention.self_attn.query.bias
        , %para159 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.8.attention.self_attn.query.weight
        , %para160 : Ref[Tensor(F32)][768]    # bert.encoder.layer.9.attention.self_attn.query.bias
        , %para161 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.9.attention.self_attn.query.weight
        , %para162 : Ref[Tensor(F32)][768]    # bert.encoder.layer.10.attention.self_attn.query.bias
        , %para163 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.10.attention.self_attn.query.weight
        , %para164 : Ref[Tensor(F32)][768]    # bert.encoder.layer.11.attention.self_attn.query.bias
        , %para165 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.11.attention.self_attn.query.weight
        , %para166 : Ref[Tensor(F32)][768]    # bert.encoder.layer.0.attention.self_attn.value.bias
        , %para167 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.0.attention.self_attn.value.weight
        , %para168 : Ref[Tensor(F32)][768]    # bert.encoder.layer.0.attention.self_attn.key.bias
        , %para169 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.0.attention.self_attn.key.weight
        , %para170 : Ref[Tensor(F32)][768]    # bert.encoder.layer.1.attention.self_attn.value.bias
        , %para171 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.1.attention.self_attn.value.weight
        , %para172 : Ref[Tensor(F32)][768]    # bert.encoder.layer.1.attention.self_attn.key.bias
        , %para173 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.1.attention.self_attn.key.weight
        , %para174 : Ref[Tensor(F32)][768]    # bert.encoder.layer.2.attention.self_attn.value.bias
        , %para175 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.2.attention.self_attn.value.weight
        , %para176 : Ref[Tensor(F32)][768]    # bert.encoder.layer.2.attention.self_attn.key.bias
        , %para177 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.2.attention.self_attn.key.weight
        , %para178 : Ref[Tensor(F32)][768]    # bert.encoder.layer.3.attention.self_attn.value.bias
        , %para179 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.3.attention.self_attn.value.weight
        , %para180 : Ref[Tensor(F32)][768]    # bert.encoder.layer.3.attention.self_attn.key.bias
        , %para181 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.3.attention.self_attn.key.weight
        , %para182 : Ref[Tensor(F32)][768]    # bert.encoder.layer.4.attention.self_attn.value.bias
        , %para183 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.4.attention.self_attn.value.weight
        , %para184 : Ref[Tensor(F32)][768]    # bert.encoder.layer.4.attention.self_attn.key.bias
        , %para185 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.4.attention.self_attn.key.weight
        , %para186 : Ref[Tensor(F32)][768]    # bert.encoder.layer.5.attention.self_attn.value.bias
        , %para187 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.5.attention.self_attn.value.weight
        , %para188 : Ref[Tensor(F32)][768]    # bert.encoder.layer.5.attention.self_attn.key.bias
        , %para189 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.5.attention.self_attn.key.weight
        , %para190 : Ref[Tensor(F32)][768]    # bert.encoder.layer.6.attention.self_attn.value.bias
        , %para191 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.6.attention.self_attn.value.weight
        , %para192 : Ref[Tensor(F32)][768]    # bert.encoder.layer.6.attention.self_attn.key.bias
        , %para193 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.6.attention.self_attn.key.weight
        , %para194 : Ref[Tensor(F32)][768]    # bert.encoder.layer.7.attention.self_attn.value.bias
        , %para195 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.7.attention.self_attn.value.weight
        , %para196 : Ref[Tensor(F32)][768]    # bert.encoder.layer.7.attention.self_attn.key.bias
        , %para197 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.7.attention.self_attn.key.weight
        , %para198 : Ref[Tensor(F32)][768]    # bert.encoder.layer.8.attention.self_attn.value.bias
        , %para199 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.8.attention.self_attn.value.weight
        , %para200 : Ref[Tensor(F32)][768]    # bert.encoder.layer.8.attention.self_attn.key.bias
        , %para201 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.8.attention.self_attn.key.weight
        , %para202 : Ref[Tensor(F32)][768]    # bert.encoder.layer.9.attention.self_attn.value.bias
        , %para203 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.9.attention.self_attn.value.weight
        , %para204 : Ref[Tensor(F32)][768]    # bert.encoder.layer.9.attention.self_attn.key.bias
        , %para205 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.9.attention.self_attn.key.weight
        , %para206 : Ref[Tensor(F32)][768]    # bert.encoder.layer.10.attention.self_attn.value.bias
        , %para207 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.10.attention.self_attn.value.weight
        , %para208 : Ref[Tensor(F32)][768]    # bert.encoder.layer.10.attention.self_attn.key.bias
        , %para209 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.10.attention.self_attn.key.weight
        , %para210 : Ref[Tensor(F32)][768]    # bert.encoder.layer.11.attention.self_attn.value.bias
        , %para211 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.11.attention.self_attn.value.weight
        , %para212 : Ref[Tensor(F32)][768]    # bert.encoder.layer.11.attention.self_attn.key.bias
        , %para213 : Ref[Tensor(F32)][768, 768]    # bert.encoder.layer.11.attention.self_attn.key.weight
    ) {

#------------------------> 0
    %1 = FuncGraph::fg_180(%para1, %para2, %para3, %para4, %para5, %para6, %para7)    #(Tensor(I32)[512, 128], Tensor(I32)[512, 128], Tensor(I32)[512, 128], NoneTypeNoShape, NoneTypeNoShape, Tensor(I32)[512, 20], Tensor(I32)[512, 1])    # fg_180=construct.180 #scope: Default
#[CNode]181
    Primitive::Return{prim_type=1}(%1)    #(Undefined) #scope: Default
      # In file /data0/bert/src/bert.py(415)/        if masked_lm_labels is not None and next_sentence_label is not None:/#[CNode]182
}
# order:
#   1: construct_wrapper.178:[CNode]181{[0]: ValueNode<FuncGraph> construct.180, [1]: input_ids, [2]: attention_mask, [3]: token_type_ids, [4]: position_ids, [5]: head_mask, [6]: masked_lm_labels, [7]: next_sentence_label}
#   2: construct_wrapper.178:[CNode]182{[0]: ValueNode<Primitive> Return, [1]: [CNode]181}


# [No.2] construct.179
# In file /data0/bert/src/bert.py(398)/    def construct(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None,/
funcgraph fg_179[fg_178](
        %para214 : Tensor(I32)[512, 128]    # input_ids
        , %para215 : Tensor(I32)[512, 128]    # attention_mask
        , %para216 : Tensor(I32)[512, 128]    # token_type_ids
        , %para217 : NoneTypeNoShape    # position_ids
        , %para218 : NoneTypeNoShape    # head_mask
        , %para219 : Tensor(I32)[512, 20]    # masked_lm_labels
        , %para220 : Tensor(I32)[512, 1]    # next_sentence_label
    ) {
    %1 : Tuple[Tensor(I32)]TupleShape((512, 128)) = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%para214)    #(Tensor(I32)[512, 128]) #scope: Default
      # In file /data0/bert/src/bert.py(400)/        outputs = self.bert(/#[CNode]183
    %2 : Tuple[String*4]TupleShape(NoShape, NoShape, NoShape, NoShape) = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}("attention_mask", "token_type_ids", "position_ids", "head_mask")    #(StringNoShape, StringNoShape, StringNoShape, StringNoShape) #scope: Default
      # In file /data0/bert/src/bert.py(400)/        outputs = self.bert(/#[CNode]184
    %3 : Tuple[Tensor(I32)*2,NoneType*2]TupleShape((512, 128), (512, 128), NoShape, NoShape) = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%para215, %para216, %para217, %para218)    #(Tensor(I32)[512, 128], Tensor(I32)[512, 128], NoneTypeNoShape, NoneTypeNoShape) #scope: Default
      # In file /data0/bert/src/bert.py(400)/        outputs = self.bert(/#[CNode]185
    %4 : Dictionary[[attention_mask,token_type_ids,position_ids,head_mask,],[Tensor[Int32]*2,None*2]]NoShape = DoSignaturePrimitive::S-Prim-make_dict{prim_type=1}(%2, %3)    #(Tuple[String*4]TupleShape(NoShape, NoShape, NoShape, NoShape), Tuple[Tensor(I32)*2,NoneType*2]TupleShape((512, 128), (512, 128), NoShape, NoShape)) #scope: Default
      # In file /data0/bert/src/bert.py(400)/        outputs = self.bert(/#[CNode]186
    %5 : Tuple[Tensor(F32)*2]TupleShape((512, 128, 768), (512, 768)) = UnpackCall::unpack_call(FuncGraph::fg_187, %1, %4)    #(FuncNoShape, Tuple[Tensor(I32)]TupleShape((512, 128)), Dictionary[[attention_mask,token_type_ids,position_ids,head_mask,],[Tensor[Int32]*2,None*2]]NoShape)    # fg_187=construct.187 #scope: Default
      # In file /data0/bert/src/bert.py(400)/        outputs = self.bert(/#outputs

#------------------------> 1
    %6 = Primitive::getattr{prim_type=1}(%5, "shape")    #(Tuple[Tensor(F32)*2]TupleShape((512, 128, 768), (512, 768)), StringNoShape) #scope: Default
      # In file /data0/bert/src/bert.py(407)/        print(outputs.shape)/#[CNode]188
    %7 = FuncGraph::fg_189(%6)    #(Undefined)    # fg_189=print_.189 #scope: Default
      # In file /data0/bert/src/bert.py(407)/        print(outputs.shape)/#[CNode]190
    %8 = DoSignaturePrimitive::S-Prim-make_slice{prim_type=1}(None, I64(2), None)    #(Undefined, Undefined, Undefined) #scope: Default
      # In file /data0/bert/src/bert.py(409)/        sequence_output, pooled_output = outputs[:2]/#[CNode]191
    %9 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%5, %8)    #(Tuple[Tensor(F32)*2]TupleShape((512, 128, 768), (512, 768)), Undefined) #scope: Default
      # In file /data0/bert/src/bert.py(409)/        sequence_output, pooled_output = outputs[:2]/#[CNode]192
    %10 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%9, I64(0))    #(Undefined, Undefined) #scope: Default
      # In file /data0/bert/src/bert.py(409)/        sequence_output, pooled_output = outputs[:2]/#sequence_output
    %11 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%9, I64(1))    #(Undefined, Undefined) #scope: Default
      # In file /data0/bert/src/bert.py(409)/        sequence_output, pooled_output = outputs[:2]/#pooled_output
    %12 = FuncGraph::fg_193(%10, %11)    #(Undefined, Undefined)    # fg_193=construct.193 #scope: Default
      # In file /data0/bert/src/bert.py(410)/        prediction_scores, seq_relationship_score = self.cls(sequence_output, pooled_output)/#[CNode]194
    %13 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%12, I64(0))    #(Undefined, Undefined) #scope: Default
      # In file /data0/bert/src/bert.py(410)/        prediction_scores, seq_relationship_score = self.cls(sequence_output, pooled_output)/#prediction_scores
    %14 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%12, I64(1))    #(Undefined, Undefined) #scope: Default
      # In file /data0/bert/src/bert.py(410)/        prediction_scores, seq_relationship_score = self.cls(sequence_output, pooled_output)/#seq_relationship_score
    %15 = DoSignaturePrimitive::S-Prim-MakeTuple{prim_type=1}(%13, %14)    #(Undefined, Undefined) #scope: Default
      # In file /data0/bert/src/bert.py(412)/        outputs = (prediction_scores, seq_relationship_score,) + outputs[2:]/#[CNode]195
    %16 = DoSignaturePrimitive::S-Prim-make_slice{prim_type=1}(I64(2), None, None)    #(Undefined, Undefined, Undefined) #scope: Default
      # In file /data0/bert/src/bert.py(412)/        outputs = (prediction_scores, seq_relationship_score,) + outputs[2:]/#[CNode]196
    %17 = DoSignaturePrimitive::S-Prim-getitem{prim_type=1}(%5, %16)    #(Tuple[Tensor(F32)*2]TupleShape((512, 128, 768), (512, 768)), Undefined) #scope: Default
      # In file /data0/bert/src/bert.py(412)/        outputs = (prediction_scores, seq_relationship_score,) + outputs[2:]/#[CNode]197
    %18 = DoSignaturePrimitive::S-Prim-add{prim_type=1}(%15, %17)    #(Undefined, Undefined) #scope: Default
      # In file /data0/bert/src/bert.py(412)/        outputs = (prediction_scores, seq_relationship_score,) + outputs[2:]/#outputs
    %19 = Primitive::getattr{prim_type=1}(%18, "shape")    #(Undefined, Undefined) #scope: Default
      # In file /data0/bert/src/bert.py(413)/        print(outputs.shape)/#[CNode]198
    %20 = FuncGraph::fg_189(%19)    #(Undefined)    # fg_189=print_.189 #scope: Default
      # In file /data0/bert/src/bert.py(413)/        print(outputs.shape)/#[CNode]199
    %21 = Primitive::MakeTuple{prim_type=1}(%7, %20)    #(Undefined, Undefined) #scope: Default
#[CNode]200
    %22 = Primitive::stop_gradient{prim_type=1}(%21)    #(Undefined) #scope: Default
#[CNode]201
    %23 = DoSignaturePrimitive::S-Prim-is_not{prim_type=1}(%para219, None)    #(Tensor(I32)[512, 20], Undefined) #scope: Default
      # In file /data0/bert/src/bert.py(415)/        if masked_lm_labels is not None and next_sentence_label is not None:/#[CNode]202
    %24 = FuncGraph::fg_203(%23)    #(Undefined)    # fg_203=bool_.203 #scope: Default
      # In file /data0/bert/src/bert.py(415)/        if masked_lm_labels is not None and next_sentence_label is not None:/#[CNode]204
    %25 = Primitive::Switch{prim_type=1}(%24, FuncGraph::fg_205, FuncGraph::fg_206)    #(Undefined, Undefined, Undefined)    # fg_205=↰construct.205, fg_206=↱construct.206 #scope: Default
      # In file /data0/bert/src/bert.py(415)/        if masked_lm_labels is not None and next_sentence_label is not None:/#[CNode]207
    %26 = %25() #scope: Default
      # In file /data0/bert/src/bert.py(415)/        if masked_lm_labels is not None and next_sentence_label is not None:/#[CNode]208
    %27 = FuncGraph::fg_203(%26)    #(Undefined)    # fg_203=bool_.203 #scope: Default
      # In file /data0/bert/src/bert.py(415)/        if masked_lm_labels is not None and next_sentence_label is not None:/#[CNode]209
    %28 = Primitive::Switch{prim_type=1}(%27, FuncGraph::fg_210, FuncGraph::fg_211)    #(Undefined, Undefined, Undefined)    # fg_210=✓construct.210, fg_211=✗construct.211 #scope: Default
      # In file /data0/bert/src/bert.py(415)/        if masked_lm_labels is not None and next_sentence_label is not None:/#[CNode]212
    %29 = %28() #scope: Default
      # In file /data0/bert/src/bert.py(415)/        if masked_lm_labels is not None and next_sentence_label is not None:/#[CNode]213
    %30 = FuncGraph::fg_214(%29)    #(Undefined)    # fg_214=↓construct.214 #scope: Default
#[CNode]215
    %31 = Primitive::Depend{prim_type=1}[side_effect_propagate=I64(1)](%30, %22)    #(Undefined, Undefined) #scope: Default
#[CNode]216
    Primitive::Return{prim_type=1}(%31)    #(Undefined) #scope: Default
      # In file /data0/bert/src/bert.py(415)/        if masked_lm_labels is not None and next_sentence_label is not None:/#[CNode]217
}
# order:
#   1: construct.179:[CNode]183{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: input_ids}
#   2: construct.179:[CNode]184{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: ValueNode<StringImm> attention_mask, [2]: ValueNode<StringImm> token_type_ids, [3]: ValueNode<StringImm> position_ids, [4]: ValueNode<StringImm> head_mask}
#   3: construct.179:[CNode]185{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: attention_mask, [2]: token_type_ids, [3]: position_ids, [4]: head_mask}
#   4: construct.179:[CNode]186{[0]: ValueNode<DoSignaturePrimitive> S-Prim-make_dict, [1]: [CNode]184, [2]: [CNode]185}
#   5: construct.179:outputs{[0]: ValueNode<UnpackCall> unpack_call.218, [1]: ValueNode<FuncGraph> construct.187, [2]: [CNode]183, [3]: [CNode]186}
#   6: construct.179:[CNode]188{[0]: ValueNode<Primitive> getattr, [1]: outputs, [2]: ValueNode<StringImm> shape}
#   7: construct.179:[CNode]190{[0]: ValueNode<FuncGraph> print_.189, [1]: [CNode]188}
#   8: construct.179:[CNode]191{[0]: ValueNode<DoSignaturePrimitive> S-Prim-make_slice, [1]: ValueNode<None> None, [2]: ValueNode<Int64Imm> 2, [3]: ValueNode<None> None}
#   9: construct.179:[CNode]192{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: outputs, [2]: [CNode]191}
#  10: construct.179:sequence_output{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]192, [2]: ValueNode<Int64Imm> 0}
#  11: construct.179:pooled_output{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]192, [2]: ValueNode<Int64Imm> 1}
#  12: construct.179:[CNode]194{[0]: ValueNode<FuncGraph> construct.193, [1]: sequence_output, [2]: pooled_output}
#  13: construct.179:prediction_scores{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]194, [2]: ValueNode<Int64Imm> 0}
#  14: construct.179:seq_relationship_score{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: [CNode]194, [2]: ValueNode<Int64Imm> 1}
#  15: construct.179:[CNode]195{[0]: ValueNode<DoSignaturePrimitive> S-Prim-MakeTuple, [1]: prediction_scores, [2]: seq_relationship_score}
#  16: construct.179:[CNode]196{[0]: ValueNode<DoSignaturePrimitive> S-Prim-make_slice, [1]: ValueNode<Int64Imm> 2, [2]: ValueNode<None> None, [3]: ValueNode<None> None}
#  17: construct.179:[CNode]197{[0]: ValueNode<DoSignaturePrimitive> S-Prim-getitem, [1]: outputs, [2]: [CNode]196}
#  18: construct.179:outputs{[0]: ValueNode<DoSignaturePrimitive> S-Prim-add, [1]: [CNode]195, [2]: [CNode]197}
#  19: construct.179:[CNode]198{[0]: ValueNode<Primitive> getattr, [1]: outputs, [2]: ValueNode<StringImm> shape}
#  20: construct.179:[CNode]199{[0]: ValueNode<FuncGraph> print_.189, [1]: [CNode]198}
#  21: construct.179:[CNode]202{[0]: ValueNode<DoSignaturePrimitive> S-Prim-is_not, [1]: masked_lm_labels, [2]: ValueNode<None> None}
#  22: construct.179:[CNode]204{[0]: ValueNode<FuncGraph> bool_.203, [1]: [CNode]202}
#  23: construct.179:[CNode]207{[0]: ValueNode<Primitive> Switch, [1]: [CNode]204, [2]: ValueNode<FuncGraph> ↰construct.205, [3]: ValueNode<FuncGraph> ↱construct.206}
#  24: construct.179:[CNode]208{[0]: [CNode]207}
#  25: construct.179:[CNode]209{[0]: ValueNode<FuncGraph> bool_.203, [1]: [CNode]208}
#  26: construct.179:[CNode]212{[0]: ValueNode<Primitive> Switch, [1]: [CNode]209, [2]: ValueNode<FuncGraph> ✓construct.210, [3]: ValueNode<FuncGraph> ✗construct.211}
#  27: construct.179:[CNode]213{[0]: [CNode]212}
#  28: construct.179:[CNode]215{[0]: ValueNode<FuncGraph> ↓construct.214, [1]: [CNode]213}
#  29: construct.179:[CNode]216{[0]: ValueNode<Primitive> Depend, [1]: [CNode]215, [2]: [CNode]201}
#  30: construct.179:[CNode]217{[0]: ValueNode<Primitive> Return, [1]: [CNode]216}


#===============================================================================
# num of function graphs in stack: 2
